/** TRACCC library, part of the ACTS project (R&D line)
 *
 * (c) 2022 CERN for the benefit of the ACTS project
 *
 * Mozilla Public License Version 2.0
 */

// Local include(s).
#include "../utils/get_queue.hpp"
#include "traccc/sycl/clusterization/clusterization_algorithm.hpp"
#include "traccc/sycl/utils/calculate1DimNdRange.hpp"

// Project include(s)
#include "traccc/clusterization/device/aggregate_cluster.hpp"
#include "traccc/clusterization/device/form_spacepoints.hpp"
#include "traccc/clusterization/device/reduce_problem_cell.hpp"

// Vecmem include(s).
#include <vecmem/memory/device_atomic_ref.hpp>
#include <vecmem/utils/sycl/copy.hpp>

// System include(s).
#include <algorithm>

namespace traccc::sycl {

namespace {
/// These indices in clusterization will only range from 0 to
/// MAX_CELLS_PER_PARTITION, so we only need a short
using index_t = unsigned short;
}  // namespace

namespace kernels {

/// Class identifying the kernel running @c traccc::device::form_spacepoints
class form_spacepoints;

/// Implementation of a FastSV algorithm with the following steps:
///   1) mix of stochastic and aggressive hooking
///   2) shortcutting
///
/// The implementation corresponds to an adapted versiion of Algorithm 3 of
/// the following paper:
/// https://www.sciencedirect.com/science/article/pii/S0743731520302689
///
/// @param[inout] f     array holding the parent cell ID for the current
/// iteration.
/// @param[inout] gf    array holding grandparent cell ID from the previous
/// iteration.
///                     This array only gets updated at the end of the iteration
///                     to prevent race conditions.
/// @param[in] adjc     The number of adjacent cells
/// @param[in] adjv     Vector of adjacent cells
/// @param[in] tid      The thread index
///
void fast_sv_1(index_t* f, index_t* gf, unsigned char adjc, index_t adjv[8],
               index_t tid, ::sycl::nd_item<1> item) {
    /*
     * The algorithm finishes if an iteration leaves the arrays unchanged.
     * This varible will be set if a change is made, and dictates if another
     * loop is necessary.
     */
    bool gf_changed;

    do {
        /*
         * Reset the end-parameter to false, so we can set it to true if we
         * make a change to the gf array.
         */
        gf_changed = false;

        /*
         * The algorithm executes in a loop of three distinct parallel
         * stages. In this first one, a mix of stochastic and aggressive
         * hooking, we examine adjacent cells and copy their grand parents
         * cluster ID if it is lower than ours, essentially merging the two
         * together.
         */
        __builtin_assume(adjc <= 8);
        for (unsigned char k = 0; k < adjc; ++k) {
            index_t q = gf[adjv[k]];

            if (gf[tid] > q) {
                f[f[tid]] = q;
                f[tid] = q;
            }
        }

        /*
         * Each stage in this algorithm must be preceded by a
         * synchronization barrier!
         */
        item.barrier();

        /*
         * The second stage is shortcutting, which is an optimisation that
         * allows us to look at any shortcuts in the cluster IDs that we
         * can merge without adjacency information.
         */
        if (f[tid] > gf[tid]) {
            f[tid] = gf[tid];
        }

        /*
         * Synchronize before the final stage.
         */
        item.barrier();

        /*
         * Update the array for the next generation, keeping track of any
         * changes we make.
         */
        if (gf[tid] != f[f[tid]]) {
            gf[tid] = f[f[tid]];
            gf_changed = true;
        }

        /*
         * To determine whether we need another iteration, we use block
         * voting mechanics. Each thread checks if it has made any changes
         * to the arrays, and votes. If any thread votes true, all threads
         * will return a true value and go to the next iteration. Only if
         * all threads return false will the loop exit.
         */
    } while (item.barrier(),
             ::sycl::any_of_group(item.get_group(), gf_changed));
}

class ccl_kernel {
    public:
    ccl_kernel(
        const alt_cell_collection_types::const_view cells,
        const cell_module_collection_types::const_view modules,
        const partition_collection_types::const_view partitions,
        const unsigned short max_cells_per_partition,
        alt_measurement_collection_types::view measurements,
        unsigned int* num_measurements,
        ::sycl::accessor<index_t, 1, ::sycl::access::mode::read_write,
                         ::sycl::access::target::local>
            father,
        ::sycl::accessor<index_t, 1, ::sycl::access::mode::read_write,
                         ::sycl::access::target::local>
            grandfather,
        ::sycl::accessor<unsigned int, 1, ::sycl::access::mode::read_write,
                         ::sycl::access::target::local>
            outCounter)
        : cells_view(cells),
          modules_view(modules),
          m_max_cells_per_partition(max_cells_per_partition),
          partitions_view(partitions),
          measurements_view(measurements),
          m_measurement_count(num_measurements),
          f(father),
          f_next(grandfather),
          m_outi(outCounter) {}

    void operator()(::sycl::nd_item<1> item) const {

        const index_t tid = item.get_local_linear_id();

        const partition_collection_types::const_device partitions_device(
            partitions_view);
        assert(item.get_group_linear_id() < partitions_device.size());

        // Get partition for this thread group
        const partition start = partitions_device[item.get_group_linear_id()];
        const partition end = partitions_device[item.get_group_linear_id() + 1];
        assert(end - start <= m_max_cells_per_partition);
        const unsigned short partition_size = end - start;

        const alt_cell_collection_types::const_device cells_device(cells_view);
        const cell_module_collection_types::const_device modules_device(
            modules_view);

        alt_measurement_collection_types::device measurements_device(
            measurements_view);

        unsigned int& outi = m_outi[0];
        unsigned int& measurement_count = m_measurement_count[0];

        // Vector of indices of the adjacent cells
        index_t adjv[8];
        /*
         * The number of adjacent cells for each cell must start at zero, to
         * avoid uninitialized memory. adjv does not need to be zeroed, as
         * we will only access those values if adjc indicates that the value
         * is set.
         */
        // Number of adjacent cells
        unsigned char adjc = 0;

        // It seems that sycl runs into undefined behaviour when calling
        // any_of_group when some threads have already run into a return. So can
        // only do this after running the FastSV algorithm.
        if (tid < partition_size) {
            /*
             * Look for adjacent cells to the current one.
             */
            device::reduce_problem_cell(cells_device, tid, start, end, adjc,
                                        adjv);
        }

        /*
         * At the start, the values of f and f_next should be equal to the
         * ID of the cell.
         */
        f[tid] = tid;
        f_next[tid] = tid;

        /*
         * Now that the data has initialized, we synchronize again before we
         * move onto the actual processing part.
         */
        item.barrier();

        /*
         * Run FastSV algorithm, which will update the father index to that of
         * the cell belonging to the same cluster with the lowest index.
         */
        fast_sv_1(&f[0], &f_next[0], adjc, adjv, tid, item);

        // Now that we can use return, check if any work needs to be done
        if (tid >= partition_size) {
            return;
        }

        /*
         * Initialize the counter of clusters per thread block
         */
        if (tid == 0) {
            outi = 0;
        }

        item.barrier();

        /*
         * Count the number of clusters by checking how many cells have
         * themself assigned as a parent.
         */
        if (f[tid] == tid) {
            ::sycl::ext::oneapi::atomic_ref<
                unsigned int, ::sycl::memory_order::relaxed,
                ::sycl::memory_scope::work_group,
                ::sycl::access::address_space::local_space>(outi)
                .fetch_add(1);
        }

        item.barrier();

        /*
         * Add the number of clusters of each thread block to the total
         * number of clusters. At the same time, a cluster id is retrieved
         * for the next data processing step.
         * Note that this might be not the same cluster as has been treated
         * previously. However, since each thread block spawns a the maximum
         * amount of threads per block, this has no sever implications.
         */
        if (tid == 0) {
            outi = ::sycl::ext::oneapi::atomic_ref<
                       unsigned int, ::sycl::memory_order::relaxed,
                       ::sycl::memory_scope::device,
                       ::sycl::access::address_space::global_space>(
                       measurement_count)
                       .fetch_add(outi);
        }

        item.barrier();

        /*
         * Get the position to fill the measurements found in this thread group.
         */
        const unsigned int groupPos = outi;

        item.barrier();

        if (tid == 0) {
            outi = 0;
        }

        item.barrier();

        const vecmem::data::vector_view<unsigned short> f_view(
            m_max_cells_per_partition, &f[0]);

        if (f[tid] == tid) {
            /*
             * If we are a cluster owner, atomically claim a position in the
             * output array which we can write to.
             */
            const unsigned int id =
                ::sycl::ext::oneapi::atomic_ref<
                    unsigned int, ::sycl::memory_order::relaxed,
                    ::sycl::memory_scope::work_group,
                    ::sycl::access::address_space::local_space>(outi)
                    .fetch_add(1);

            device::aggregate_cluster(cells_device, modules_device, f_view,
                                      start, end, tid,
                                      measurements_device[groupPos + id]);
        }
    }

    private:
    const alt_cell_collection_types::const_view cells_view;
    const cell_module_collection_types::const_view modules_view;
    const unsigned short m_max_cells_per_partition;
    const partition_collection_types::const_view partitions_view;
    alt_measurement_collection_types::view measurements_view;
    unsigned int* m_measurement_count;
    ::sycl::accessor<index_t, 1, ::sycl::access::mode::read_write,
                     ::sycl::access::target::local>
        f;
    ::sycl::accessor<index_t, 1, ::sycl::access::mode::read_write,
                     ::sycl::access::target::local>
        f_next;
    ::sycl::accessor<unsigned int, 1, ::sycl::access::mode::read_write,
                     ::sycl::access::target::local>
        m_outi;
};

}  // namespace kernels

clusterization_algorithm::clusterization_algorithm(
    const traccc::memory_resource& mr, queue_wrapper queue,
    const unsigned short max_cells_per_partition)
    : m_max_cells_per_partition(max_cells_per_partition),
      m_mr(mr),
      m_queue(queue) {

    // Initialize m_copy ptr based on memory resources that were given
    if (mr.host) {
        m_copy = std::make_unique<vecmem::sycl::copy>(queue.queue());
    } else {
        m_copy = std::make_unique<vecmem::copy>();
    }
}

clusterization_algorithm::output_type clusterization_algorithm::operator()(
    const alt_cell_collection_types::const_view& cells,
    const cell_module_collection_types::const_view& modules,
    const partition_collection_types::const_view& partitions) const {

    // Number of cells
    const alt_cell_collection_types::view::size_type num_cells =
        m_copy->get_size(cells);
    // Number of cell partitions
    const partition_collection_types::view::size_type num_partitions =
        m_copy->get_size(partitions) - 1;

    // Create result object for the CCL kernel with size overestimation
    alt_measurement_collection_types::buffer measurements_buffer(num_cells,
                                                                 m_mr.main);
    alt_measurement_collection_types::view measurements_view(
        measurements_buffer);

    // Counter for number of measurements
    vecmem::unique_alloc_ptr<unsigned int> num_measurements_device =
        vecmem::make_unique_alloc<unsigned int>(m_mr.main);
    details::get_queue(m_queue)
        .memset(num_measurements_device.get(), 0, sizeof(unsigned int))
        .wait_and_throw();

    const unsigned short max_cells_per_partition = m_max_cells_per_partition;
    ::sycl::nd_range ndrange(
        ::sycl::range<1>(num_partitions * max_cells_per_partition),
        ::sycl::range<1>(max_cells_per_partition));

    // Run ccl kernel
    details::get_queue(m_queue)
        .submit([&ndrange, &cells, &modules, max_cells_per_partition,
                 &partitions, &measurements_view,
                 &num_measurements_device](::sycl::handler& h) {
            ::sycl::accessor<index_t, 1, ::sycl::access::mode::read_write,
                             ::sycl::access::target::local>
                f(max_cells_per_partition, h);
            ::sycl::accessor<index_t, 1, ::sycl::access::mode::read_write,
                             ::sycl::access::target::local>
                f_next(max_cells_per_partition, h);
            ::sycl::accessor<unsigned int, 1, ::sycl::access::mode::read_write,
                             ::sycl::access::target::local>
                outi(1, h);

            h.parallel_for<kernels::ccl_kernel>(
                ndrange, kernels::ccl_kernel(
                             cells, modules, partitions,
                             max_cells_per_partition, measurements_view,
                             num_measurements_device.get(), f, f_next, outi));
        })
        .wait_and_throw();

    // Copy number of measurements to host
    unsigned int num_measurements_host;
    details::get_queue(m_queue)
        .memcpy(&num_measurements_host, num_measurements_device.get(),
                sizeof(unsigned int))
        .wait_and_throw();

    spacepoint_collection_types::buffer spacepoints_buffer(
        num_measurements_host, m_mr.main);
    spacepoint_collection_types::view spacepoints_view(spacepoints_buffer);

    // For the following kernel, we can now use whatever the desired number of
    // threads. Chose to use max_cells_per_partition.
    auto spacepointsRange = traccc::sycl::calculate1DimNdRange(
        num_measurements_host, max_cells_per_partition);

    // Run form spacepoints kernel, turning 2D measurements into 3D spacepoints
    details::get_queue(m_queue)
        .submit([&](::sycl::handler& h) {
            h.parallel_for<kernels::form_spacepoints>(
                spacepointsRange,
                [measurements_view, modules, num_measurements_host,
                 spacepoints_view](::sycl::nd_item<1> item) {
                    device::form_spacepoints(
                        item.get_global_linear_id(), measurements_view, modules,
                        num_measurements_host, spacepoints_view);
                });
        })
        .wait_and_throw();

    return spacepoints_buffer;
}

}  // namespace traccc::sycl